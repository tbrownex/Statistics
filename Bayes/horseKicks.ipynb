{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://barnesanalytics.com/bayesian-poisson-ab-testing-in-pymc3-on-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "matplotlib_style = 'fivethirtyeight' #@param ['fivethirtyeight', 'bmh', 'ggplot', 'seaborn', 'default', 'Solarize_Light2', 'classic', 'dark_background', 'seaborn-colorblind', 'seaborn-notebook']\n",
    "import matplotlib.pyplot as plt; plt.style.use(matplotlib_style)\n",
    "import matplotlib.axes as axes;\n",
    "from matplotlib.patches import Ellipse\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set_context('notebook')\n",
    "from IPython.core.pylabtools import figsize\n",
    "#@markdown This sets the resolution of the plot outputs (`retina` is the highest resolution)\n",
    "notebook_screen_res = 'retina' #@param ['retina', 'png', 'jpeg', 'svg', 'pdf']\n",
    "%config InlineBackend.figure_format = notebook_screen_res\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/tbrownex/data/Bayes/HorseKicks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model the count by year as a Possion distribution so need to figure out Lamba for each corps\n",
    "# Set initial value of Lambda as the inverse of the average across all the data\n",
    "tmp = df.copy(deep=True)\n",
    "tmp.drop(columns=\"Year\", inplace=True)\n",
    "alpha = 1.0 /np.array(tmp).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index=df[\"Year\"]\n",
    "df.drop(columns=\"Year\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_log_prob(data, alpha):\n",
    "    tfd = tfp.distributions\n",
    "    rvLambda       = tfd.Exponential(rate=alpha)\n",
    "    rvObservation = tfd.Poisson(rate=rvLambda)\n",
    "    return (rvLambda_1.log_prob(Lambda) + tf.reduce_sum(rvObservation.log_prob(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data, alpha):\n",
    "    with mc.Model() as model:\n",
    "        Lambda      = mc.Exponential(\"lambda\", alpha)\n",
    "        observation = mc.Poisson(rate=Lambda)\n",
    "        return ( tf.reduce_sum(observation.log_prob(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the dataframe column into a Tensor with shape [-1,]\n",
    "def formatData(df, col):\n",
    "    return tf.convert_to_tensor(value=df[col].values,\n",
    "                                dtype=tf.float32,\n",
    "                                name=\"colData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "alpha = np.array(1. / data.mean(), np.float32)\n",
    "\n",
    "for col in df.columns:\n",
    "    data = formatData(df, col)\n",
    "    process(data, alpha)\n",
    "    print(\"done\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the chain's start state.\n",
    "initial_chain_state = [\n",
    "    tf.cast(tf.reduce_mean(count_data), tf.float32) * tf.ones([], dtype=tf.float32, name=\"init_lambda1\"),\n",
    "    tf.cast(tf.reduce_mean(count_data), tf.float32) * tf.ones([], dtype=tf.float32, name=\"init_lambda2\", tf.float32),\n",
    "    0.5 * tf.ones([], dtype=tf.float32, name=\"init_tau\"),\n",
    "]\n",
    "\n",
    "\n",
    "# Since HMC operates over unconstrained space, we need to transform the\n",
    "# samples so they live in real-space.\n",
    "unconstraining_bijectors = [\n",
    "    tfp.bijectors.Exp(),       # Maps a positive real to R.\n",
    "    tfp.bijectors.Exp(),       # Maps a positive real to R.\n",
    "    tfp.bijectors.Sigmoid(),   # Maps [0,1] to R.  \n",
    "]\n",
    "\n",
    "\n",
    "def joint_log_prob(count_data, lambda_1, lambda_2, tau):\n",
    "    tfd = tfp.distributions\n",
    " \n",
    "    alpha = (1. / tf.reduce_mean(count_data))\n",
    "    rv_lambda_1 = tfd.Exponential(rate=alpha)\n",
    "    rv_lambda_2 = tfd.Exponential(rate=alpha)\n",
    " \n",
    "    rv_tau = tfd.Uniform()\n",
    " \n",
    "\n",
    "    lambda_ = tf.gather(\n",
    "         [lambda_1, lambda_2],\n",
    "         indices=tf.to_int32(tau * tf.cast(tf.size(count_data), tf.float32) <= tf.cast(tf.range(tf.size(count_data)), tf.float32)))\n",
    "    rv_observation = tfd.Poisson(rate=lambda_)\n",
    " \n",
    "    return (\n",
    "         rv_lambda_1.log_prob(lambda_1)\n",
    "         + tf.reduce_sum(rv_observation.log_prob(count_data))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a closure over our joint_log_prob.\n",
    "def unnormalized_log_posterior(lambda1, lambda2, tau):\n",
    "    return joint_log_prob(count_data, lambda1, lambda2, tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the step_size. (It will be automatically adapted.)\n",
    "with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):\n",
    "    step_size = tf.get_variable(\n",
    "        name='step_size',\n",
    "        initializer=tf.constant(0.05, dtype=tf.float32),\n",
    "        trainable=False,\n",
    "        use_resource=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from the chain.\n",
    "[lambda_samples,], kernel_results = tfp.mcmc.sample_chain(\n",
    "    num_results=100000,\n",
    "    num_burnin_steps=10000,\n",
    "    current_state=initial_chain_state,\n",
    "    kernel=tfp.mcmc.TransformedTransitionKernel(\n",
    "        inner_kernel=tfp.mcmc.HamiltonianMonteCarlo(\n",
    "            target_log_prob_fn=unnormalized_log_posterior,\n",
    "            num_leapfrog_steps=2,\n",
    "            step_size=step_size,\n",
    "            step_size_update_fn=tfp.mcmc.make_simple_step_size_update_policy(),\n",
    "            state_gradients_are_stopped=True),\n",
    "        bijector=unconstraining_bijectors))\n",
    "\n",
    "# tau_samples, lambda_1_samples, lambda_2_samples contain\n",
    "# N samples from the corresponding posterior distribution\n",
    "N = tf.shape(lambda_samples)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    [lambda_samples_,kernel_results_,N_,texts_per_day_,] = sess.run([lambda_samples,\n",
    "                                                                     kernel_results,\n",
    "                                                                     N,\n",
    "                                                                     expected_texts_per_day,])\n",
    "print(\"acceptance rate: {}\".format(\n",
    "    kernel_results_.inner_results.is_accepted.mean()))\n",
    "print(\"final step size: {}\".format(\n",
    "    kernel_results_.inner_results.extra.step_size_assign[-100:].mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
